{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff8c7bc5",
   "metadata": {},
   "source": [
    "# CV - Image Classification - Segmentation - Autoencoders\n",
    "\n",
    "Note that this lab has three levels: basic, regular and advanced.\n",
    "\n",
    "\n",
    "Doing the **basic** part earns you a grade of 5.5-6.0.\n",
    "\n",
    "Doing the **regular** part earns you a max grade of 8.0.\n",
    "\n",
    "Doing the **advanced** part earns you a max grade of 10.0.\n",
    "\n",
    "Please return a Jupyter notebook as a submission in Canvas, to make the grading easier for us.\n",
    "\n",
    "## Basic Level\n",
    "\n",
    "Exploring the basic concepts discussed in the lecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29dd2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import cifar10, mnist, cifar100\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation,BatchNormalization, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications import EfficientNetV2S, ResNet50, vgg16\n",
    "from keras.utils import to_categorical \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "from keras.metrics import MeanIoU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical \n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.special import softmax\n",
    "from keras.layers import LeakyReLU\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import  Input, Dense, BatchNormalization, Conv2D, Dropout, Conv2DTranspose, Concatenate\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation,BatchNormalization, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "from skimage import io\n",
    "from skimage.util import random_noise\n",
    "from skimage.transform import rotate, AffineTransform,warp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bfc929d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5e2999",
   "metadata": {},
   "source": [
    "## Classification and Transfer Learning\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "In this exercise, we will work with the CIFAR100 dataset. \n",
    "\n",
    "The dataset can be import from keras datasets directly. No preprocessing is needed, you can directly use it to learn a model.\n",
    "\n",
    "The CIFAR100 dataset has a 100 classes, each with 600 examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce40fa",
   "metadata": {},
   "source": [
    "a. Let's load the dataset from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de06d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y)=cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12bbbfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8876b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y=to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b9506",
   "metadata": {},
   "source": [
    "b. Let's create a CNN model to learn to classify the data.\n",
    "\n",
    "Create your model using the functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e6cc4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_basic\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 8)         224       \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 32, 32, 16)        1168      \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                1048640   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               6500      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,056,532\n",
      "Trainable params: 1,056,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3ec949",
   "metadata": {},
   "source": [
    "c. compile and fit the model to the data.\n",
    "\n",
    "This process might take too long, set the number of epochs to some low value. The goal of this part is to show that this classification problem (100 classes) is complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80953d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d596741",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/782 [..............................] - ETA: 1:32 - loss: 4.6071 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BoualiN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 56s 72ms/step - loss: 4.6058 - acc: 0.0088 - val_loss: 4.6052 - val_acc: 0.0100\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 56s 72ms/step - loss: 4.6057 - acc: 0.0088 - val_loss: 4.6052 - val_acc: 0.0100\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 57s 72ms/step - loss: 4.6057 - acc: 0.0085 - val_loss: 4.6052 - val_acc: 0.0100\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 57s 73ms/step - loss: 4.6057 - acc: 0.0089 - val_loss: 4.6052 - val_acc: 0.0100\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 58s 75ms/step - loss: 4.6057 - acc: 0.0086 - val_loss: 4.6052 - val_acc: 0.0100\n"
     ]
    }
   ],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f58f08",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The model trained on CIFAR100 is probably not giving the best results you can achieve. \n",
    "\n",
    "Let's train the same model on CIFAR10, a version of CIFAR with only 10 classes instead of a 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e47dbd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bda1fa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y=to_categorical(train_y)\n",
    "test_y=to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd46fa5b",
   "metadata": {},
   "source": [
    "a. Recreate your basic model here, compile it and fit it to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9795f70d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/782 [..............................] - ETA: 1:14 - loss: 69.8884 - acc: 0.0781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BoualiN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 57s 73ms/step - loss: 3.5189 - acc: 0.3248 - val_loss: 1.7133 - val_acc: 0.3933\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 61s 79ms/step - loss: 1.4997 - acc: 0.4687 - val_loss: 1.6953 - val_acc: 0.4154\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 58s 75ms/step - loss: 1.2227 - acc: 0.5659 - val_loss: 1.7888 - val_acc: 0.4357\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 57s 73ms/step - loss: 0.9839 - acc: 0.6523 - val_loss: 1.8384 - val_acc: 0.4490\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 57s 73ms/step - loss: 0.7803 - acc: 0.7269 - val_loss: 2.0350 - val_acc: 0.4491\n"
     ]
    }
   ],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7b918",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Our basic CNN model does better on the CIFAR10 dataset than it did on the CIFAR100. \n",
    "\n",
    "The CIFAR10 is less comples, distinguishing 10 classes is a lot less complex than distinguishing a 100.\n",
    "\n",
    "We can use transfer learning to solve this complex problem. We'll reuse the ResNet50 pretrained model from Keras, and adapt it to work on the CIFAR100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d943447",
   "metadata": {},
   "source": [
    "a. Load Resnet50 from keras. Use the **imagenet** weights.\n",
    "\n",
    "You can refer to keras to learn how to use this pretrained model, [here](https://keras.io/api/applications/resnet/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c7751df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a9d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing the layers names and inputs\n",
    "for i, layer in enumerate(pretrained.layers):\n",
    "    print(i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f564ebf5",
   "metadata": {},
   "source": [
    "b. Make sure all (or at least some) layers in the pretrained ResNet-50 are not trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d3da005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b61842",
   "metadata": {},
   "source": [
    "c. Add an output layer adequate to the task we have (predicting a 100 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33640e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 1, 1, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 16)                32784     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 100)               1700      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,622,196\n",
      "Trainable params: 34,484\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4abcd7b",
   "metadata": {},
   "source": [
    "d. Compile and train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c41eecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1fee6bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 1849s 1s/step - loss: 3.5591 - accuracy: 0.1585 - val_loss: 3.1417 - val_accuracy: 0.2301\n"
     ]
    }
   ],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85167f5a",
   "metadata": {},
   "source": [
    "As you train the model longer, the model will improve its accuracy.\n",
    "\n",
    "The dataset is balanced, so \"accuracy\" is an adequate performance metric here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddebb53",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "ResNet50 shows that it can help with the CIFAR100 problem.\n",
    "\n",
    "Let's now check whether it will allow us improve our predictions on the Breast Cancer dataset we worked with in the fist lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c288275",
   "metadata": {},
   "source": [
    "a. First, reload your images from the same dataset as before. \n",
    "\n",
    "Load the images in a data structure, and their correponding labels in another. Make sure that the images are aligned with their labels.\n",
    "\n",
    "Notice that the dataset has now the images used in the first lab and their corresponding masks. We will need the masks for the segmentation exercises. Do not use them for this classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec0fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bda443",
   "metadata": {},
   "source": [
    "b. Resize our images. Choose The size you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277052c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f46998",
   "metadata": {},
   "source": [
    "c. Convert the images to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba50bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ddc0c",
   "metadata": {},
   "source": [
    "d. Rescale the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2676360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42117ad1",
   "metadata": {},
   "source": [
    "e. We'll work on the multiclass classification problem. Create a **y** vector with the labels 0 for **normal**, 1 for **benign** and 2 for **malignant**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaae37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bfa4c7a",
   "metadata": {},
   "source": [
    "f. Let's now create a train and test set from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef893091",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(np_images, y, test_size=0.2, shuffle=True, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc72f203",
   "metadata": {},
   "source": [
    "g. Create a model based on the ResNet50 model and see whether the results of the classification improve compared to the model you developed in the previous lab.\n",
    "\n",
    "Note that ResNet50 might not be the best pretrained model for all tasks, keras offers other pretrained models. You can try any one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0759115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a127886",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13018015",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Plot the training acc and val_acc\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Check its accuracy on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fe747e",
   "metadata": {},
   "source": [
    "## Image Segmentation\n",
    "Let's now shift to work on image segmentation. \n",
    "We have discussed the topic in the lecture, and said that this is a supervised learning problem in which the model learns a mapping between the image and its mask.\n",
    "\n",
    "### Exercise 5\n",
    "\n",
    "Let's load the images from our dataset again, this time with their corresponding masks as well.\n",
    "\n",
    "Make an X data structure with the images, and a Y data structure with the masks.\n",
    "\n",
    "Check that the images are aligned with their masks, otherwise the training won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb328459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb938a8",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Convert both images and masks from RGB mode to grayscale, and resize both to a size you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a92b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ac7b3",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "Convert your images to numpy arrays.\n",
    "The shape of the masks should be (ne=766, height, width), same goes for the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6022b39",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "We have 766 examples with their corresponding masks, our semantic segmentation model will need more to be able to yield better results.\n",
    "\n",
    "Apply some data augmentation techniques to generate new data.\n",
    "\n",
    "Keep in mind that the masks need to be subjected to the same transformations you apply to the images. (if you rotate an image by 25 degrees, the mask should also be rotated with the same value). \n",
    "\n",
    "Creating 5 images from each image should give you around 3830 data points with their masks, which should be enough.\n",
    "\n",
    "Check Scikit-Image for data augmentation functions that you can use, [here](https://scikit-image.org/docs/dev/api/skimage.transform.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d83a0d8",
   "metadata": {},
   "source": [
    "Make sure you create a test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f94c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(images, masks, test_size=0.25, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a63bdd",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "Defining your U-NET architecture below. \n",
    "\n",
    "Make sure to use Keras' functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6bbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db55093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8aa179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a8acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72f8c2c",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "\n",
    "Compile and train your model. \n",
    "\n",
    "This might take quite some time if you're not training on a GPU.\n",
    "\n",
    "Use the university's Jupyter environment [here](https://jupyter.utwente.nl/) or refer to Google Colab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a736f00",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "Make the predictions based on your trained model, and show for a few examples (3 should be enough), the difference between what your model predicted and the ground truth mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98187d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e27d2e",
   "metadata": {},
   "source": [
    "## Denoising Autoencoders\n",
    "### Exercise 11\n",
    "Let's now practice autoencoder architectures that we discussed in the lecture.\n",
    "\n",
    "We'll focus on denoising autoencoders.\n",
    "\n",
    "First, let's load our dataset, and apply some noise to the images. \n",
    "\n",
    "You can apply any type of noise you want, refer to [here](https://scikit-image.org/docs/stable/api/skimage.util.html#skimage.util.random_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd446c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319535a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(noised_X, X, test_size=0.25, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6122f9",
   "metadata": {},
   "source": [
    "### Exercise 13\n",
    "Create your encoder architecture.\n",
    "\n",
    "This should output the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59958910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e748cb9",
   "metadata": {},
   "source": [
    "### Exercise 14\n",
    "Create your decoder architecture.\n",
    "\n",
    "This should input the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c239542c",
   "metadata": {},
   "source": [
    "### Exercise 15\n",
    "\n",
    "Compile the autoencoder now that you have both components.\n",
    "\n",
    "Train the autoencoder for a number of epochs of your choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7639a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1f80f",
   "metadata": {},
   "source": [
    "### Exercise 16\n",
    "\n",
    "Use the model to denoise the images on your test set, and show a comparison of your model's work and the ground truth (3 samples will suffice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901340b1",
   "metadata": {},
   "source": [
    "## Regular Part\n",
    "\n",
    "In this part, we wish to explore how to deploy a model and make it accessible to users.\n",
    "\n",
    "### Exercise 17\n",
    "\n",
    "Save one of your classification models above in the  **h5** format. \n",
    "\n",
    "Create a web app (as simple as possible) where a user can upload an image, the app should then respond with its class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e2e816",
   "metadata": {},
   "source": [
    "## Advanced Part\n",
    "\n",
    "In this part, we wish to explore how to deploy a more complex model and make it accessible to users.\n",
    "\n",
    "### Exercise 18\n",
    "\n",
    "Save your denoising autoencoder model above in the  **h5** format. \n",
    "\n",
    "Create a web app (as simple as possible) where a user can upload an image, the app should then respond with its denoised version."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
